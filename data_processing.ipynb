{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe4d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSONL files saved. Ready for upload.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def to_chatml(row):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"You are an expert fortune-telling advisor.\"},\n",
    "            {\"role\": \"user\", \"content\": row[\"question\"]},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"answer\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"data/fortune_train.csv\")\n",
    "val = pd.read_csv(\"data/fortune_test.csv\")\n",
    "\n",
    "pathlib.Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "(train.apply(to_chatml, axis=1)\n",
    "      .to_json(\"fortune_train.jsonl\", orient=\"records\", lines=True, force_ascii=False))\n",
    "(val  .apply(to_chatml, axis=1)\n",
    "      .to_json(\"fortune_val.jsonl\",   orient=\"records\", lines=True, force_ascii=False))\n",
    "\n",
    "print(\"✅ JSONL files saved. Ready for upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311772a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((165, 3), (42, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1fb8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcdfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d82d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fec0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e453354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc76841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4458bf9aec972f36",
   "metadata": {},
   "source": [
    "# Format the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T00:51:09.716309Z",
     "start_time": "2025-02-24T00:51:09.704264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def format_for_training(df):\n",
    "    \"\"\"\n",
    "    Format dataset into OpenAI's ChatCompletion format.\n",
    "    Returns a list of conversation dictionaries.\n",
    "    \"\"\"\n",
    "    formatted_data = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Create a conversation instance\n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert voice and performance analyst. Your role is to provide detailed voice descriptions for various types of content, including movies, commercials, news broadcasts, narratives, and other media. you only return with one valid json attribute(voice_description), which describes the appropriate voice characteristics, emotional tone, pacing, and delivery style that would effectively convey the intended message and impact in 20 words max.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Content: \"{row['raw_text']}\"\n",
    "\n",
    "Please provide a detailed voice description (20 words max) for delivering this content.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": json.loads(row['rewrite_response'])['voice_description']\n",
    "            }\n",
    "        ]\n",
    "        formatted_data.append(conversation)\n",
    "    \n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d194d9c80565918",
   "metadata": {},
   "source": [
    "# Train Validation Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfbc60a021d966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T00:51:13.905545Z",
     "start_time": "2025-02-24T00:51:13.864484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Distribution:\n",
      "Total samples: 400\n",
      "Training samples: 280 (70.0%)\n",
      "Test samples: 120 (30.0%)\n",
      "\n",
      "Type distribution in original data:\n",
      "type\n",
      "commercial    0.25\n",
      "horror        0.25\n",
      "movie         0.25\n",
      "news          0.25\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Type distribution in training set:\n",
      "type\n",
      "commercial    0.25\n",
      "news          0.25\n",
      "horror        0.25\n",
      "movie         0.25\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Type distribution in test set:\n",
      "type\n",
      "news          0.25\n",
      "horror        0.25\n",
      "commercial    0.25\n",
      "movie         0.25\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../synthsized_dataset/combined_dataset.csv')\n",
    "\n",
    "# First, stratify the data by type\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,  # 30% for test set\n",
    "    stratify=df['type'],\n",
    "    random_state=42  # for reproducibility\n",
    ")\n",
    "\n",
    "# Format the train data\n",
    "train_formatted = format_for_training(train_df)\n",
    "\n",
    "# Format the test data\n",
    "test_formatted = format_for_training(test_df)\n",
    "\n",
    "# Save train data to JSONL\n",
    "with open('data/voice_train.jsonl', 'w') as f:\n",
    "    for conversation in train_formatted:\n",
    "        f.write(json.dumps({\"messages\": conversation}) + '\\n')\n",
    "\n",
    "# Save test data to JSONL\n",
    "with open('data/voice_test.jsonl', 'w') as f:\n",
    "    for conversation in test_formatted:\n",
    "        f.write(json.dumps({\"messages\": conversation}) + '\\n')\n",
    "\n",
    "# Print distribution statistics\n",
    "print(\"\\nData Distribution:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Training samples: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test samples: {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "print(\"\\nType distribution in original data:\")\n",
    "print(df['type'].value_counts(normalize=True))\n",
    "print(\"\\nType distribution in training set:\")\n",
    "print(train_df['type'].value_counts(normalize=True))\n",
    "print(\"\\nType distribution in test set:\")\n",
    "print(test_df['type'].value_counts(normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
